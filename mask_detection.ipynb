{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mask detection",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7XLr5VFuqdF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEVDogdbu1TF",
        "outputId": "d9fd27b7-bc83-4f84-8526-7fcde7d93d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU98t-LYvazV"
      },
      "source": [
        "import keras "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De4_t5GzvmAv"
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jk9Fc6Rvmgi"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H46ZjqtuvmkM"
      },
      "source": [
        "from keras.optimizers import Adam"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dAs4tpAvbB6"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZZCH7kNvdP_"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU6u-TCNweiN"
      },
      "source": [
        "train_path = \"/content/drive/My Drive/dataset/train\"\n",
        "valid_path = \"/content/drive/My Drive/dataset/valid\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dizQMsoxwoio"
      },
      "source": [
        "traning_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                      rotation_range=40,\n",
        "                                      width_shift_range=0.2,\n",
        "                                      height_shift_range=0.2,\n",
        "                                      shear_range=0.2,\n",
        "                                      zoom_range=0.2,\n",
        "                                      horizontal_flip=True,\n",
        "                                      fill_mode='nearest')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTJABtDjwz0k",
        "outputId": "ea431138-2399-49b9-c509-af724b784958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "traning_data = traning_datagen.flow_from_directory(train_path,target_size=(200,200),batch_size=15,class_mode=\"binary\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3710 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOJmhtYLxOlj",
        "outputId": "edc54d51-88d4-4e3d-8668-5efb317d444d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "traning_data.class_indices"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'with_mask': 0, 'without_mask': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sSDz6exyC0G"
      },
      "source": [
        "valid_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hskiXSrUyYim",
        "outputId": "0814c57b-6301-441a-f166-3182969c633d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "valid_data = valid_datagen.flow_from_directory(valid_path,target_size=(200,200),batch_size=15,class_mode=\"binary\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 811 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARKOu3OkyyKB"
      },
      "source": [
        "model_path = \"/content/drive/My Drive/dl model.h5\""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaH439L_z38e"
      },
      "source": [
        "checkpoint = ModelCheckpoint(model_path,monitor=\"val_loss\",verbose = 1,save_best_only=True,mode=\"max\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSMBKzAE0cbB"
      },
      "source": [
        "callbacks_list = [checkpoint] "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edSax68q09V1"
      },
      "source": [
        "cnn_model = keras.models.Sequential([\n",
        "                                     keras.layers.Conv2D(filters=32,kernel_size=5,input_shape = [200,200,3]),\n",
        "                                     keras.layers.MaxPool2D(pool_size = (4,4)),\n",
        "                                     keras.layers.Conv2D(filters=64,kernel_size=4),\n",
        "                                     keras.layers.MaxPool2D(pool_size = (3,3)),\n",
        "                                     keras.layers.Conv2D(filters=128,kernel_size=3),\n",
        "                                     keras.layers.MaxPool2D(pool_size = (2,2)),\n",
        "                                     keras.layers.Conv2D(filters=256,kernel_size=2),\n",
        "                                     keras.layers.MaxPool2D(pool_size = (2,2)),\n",
        "\n",
        "                                     keras.layers.Dropout(0.5),\n",
        "                                     keras.layers.Flatten(),\n",
        "                                     keras.layers.Dense(units = 128,activation=\"relu\"),\n",
        "                                     keras.layers.Dropout(0.1),\n",
        "                                     keras.layers.Dense(units = 256,activation=\"relu\"),\n",
        "                                     keras.layers.Dropout(0.25),\n",
        "                                     keras.layers.Dense(units=2,activation=\"softmax\")])\n",
        "\n",
        "                                                          \n",
        "                                                        "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1Zl7Dwl4mKb"
      },
      "source": [
        "cnn_model.compile(optimizer=Adam(learning_rate=0.001),loss = \"sparse_categorical_crossentropy\",metrics = [\"accuracy\"])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Of8ATqr5iaX",
        "outputId": "80e4cd33-9a09-41fa-8c8b-93791df76b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "history = cnn_model.fit(traning_data,epochs = 10,verbose = 1,validation_data=valid_data,callbacks=callbacks_list)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 19/248 [=>............................] - ETA: 16:32 - loss: 0.6753 - accuracy: 0.6105"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "248/248 [==============================] - ETA: 0s - loss: 0.4514 - accuracy: 0.8081\n",
            "Epoch 00001: val_loss improved from -inf to 0.19691, saving model to /content/drive/My Drive/dl model.h5\n",
            "248/248 [==============================] - 1360s 5s/step - loss: 0.4514 - accuracy: 0.8081 - val_loss: 0.1969 - val_accuracy: 0.9359\n",
            "Epoch 2/10\n",
            "248/248 [==============================] - ETA: 0s - loss: 0.3448 - accuracy: 0.8677\n",
            "Epoch 00002: val_loss improved from 0.19691 to 0.24261, saving model to /content/drive/My Drive/dl model.h5\n",
            "248/248 [==============================] - 54s 218ms/step - loss: 0.3448 - accuracy: 0.8677 - val_loss: 0.2426 - val_accuracy: 0.9162\n",
            "Epoch 3/10\n",
            "248/248 [==============================] - ETA: 0s - loss: 0.3194 - accuracy: 0.8811\n",
            "Epoch 00003: val_loss did not improve from 0.24261\n",
            "248/248 [==============================] - 54s 216ms/step - loss: 0.3194 - accuracy: 0.8811 - val_loss: 0.1732 - val_accuracy: 0.9383\n",
            "Epoch 4/10\n",
            "248/248 [==============================] - ETA: 0s - loss: 0.3027 - accuracy: 0.8900\n",
            "Epoch 00004: val_loss did not improve from 0.24261\n",
            "248/248 [==============================] - 54s 216ms/step - loss: 0.3027 - accuracy: 0.8900 - val_loss: 0.2266 - val_accuracy: 0.9125\n",
            "Epoch 5/10\n",
            "248/248 [==============================] - ETA: 0s - loss: 0.2916 - accuracy: 0.8935\n",
            "Epoch 00005: val_loss did not improve from 0.24261\n",
            "248/248 [==============================] - 52s 211ms/step - loss: 0.2916 - accuracy: 0.8935 - val_loss: 0.2243 - val_accuracy: 0.9322\n",
            "Epoch 6/10\n",
            "248/248 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.9005\n",
            "Epoch 00006: val_loss did not improve from 0.24261\n",
            "248/248 [==============================] - 52s 211ms/step - loss: 0.2602 - accuracy: 0.9005 - val_loss: 0.1737 - val_accuracy: 0.9396\n",
            "Epoch 7/10\n",
            "248/248 [==============================] - ETA: 0s - loss: 0.2737 - accuracy: 0.8981\n",
            "Epoch 00007: val_loss did not improve from 0.24261\n",
            "248/248 [==============================] - 53s 212ms/step - loss: 0.2737 - accuracy: 0.8981 - val_loss: 0.1758 - val_accuracy: 0.9470\n",
            "Epoch 8/10\n",
            "248/248 [==============================] - ETA: 0s - loss: 0.2923 - accuracy: 0.8962\n",
            "Epoch 00008: val_loss did not improve from 0.24261\n",
            "248/248 [==============================] - 53s 216ms/step - loss: 0.2923 - accuracy: 0.8962 - val_loss: 0.1973 - val_accuracy: 0.9470\n",
            "Epoch 9/10\n",
            "248/248 [==============================] - ETA: 0s - loss: 0.2765 - accuracy: 0.9051\n",
            "Epoch 00009: val_loss did not improve from 0.24261\n",
            "248/248 [==============================] - 53s 213ms/step - loss: 0.2765 - accuracy: 0.9051 - val_loss: 0.2076 - val_accuracy: 0.9420\n",
            "Epoch 10/10\n",
            "248/248 [==============================] - ETA: 0s - loss: 0.2686 - accuracy: 0.9132\n",
            "Epoch 00010: val_loss did not improve from 0.24261\n",
            "248/248 [==============================] - 52s 211ms/step - loss: 0.2686 - accuracy: 0.9132 - val_loss: 0.2312 - val_accuracy: 0.9088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoN9pJ2P6ORn"
      },
      "source": [
        "cnn_model.save(\"/content/drive/My Drive/dl model.h5\")"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke6lFizlCX_J"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVJODttlBsDD",
        "outputId": "091df723-8f63-480a-dd1b-ae598261d177",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "plt.plot(history['loss'], label='train loss')\n",
        "plt.plot(history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        " \n",
        "# plot the accuracy\n",
        "plt.plot(history['accuracy'], label='train acc')\n",
        "plt.plot(history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-2c6c8282a2ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LossVal_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMXxi5WMCUrE",
        "outputId": "068d1bee-5f8a-46ed-b866-b4ff8c5b4136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cnn_model.history[]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fde8bfa93c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-867GWKDjFX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}